# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eq2goiM5Koybn_MCeBx1653c14SpmCkL
"""

# !pip cache purge

# !pip install openAI

# !pip install LangChain
# !pip install streamlit

# !pip install LangChain==0.0.148

# !pip install pydantic==1.10.6
# !pip install typing-inspect==0.8.0

import streamlit as st
from langchain import OpenAI,LLMChain
from langchain.prompts import PromptTemplate
import os
#set you API key

os.environ["OPENAI_API_KEY"] = "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"

#define you LangChain app
prompt_template="you are a helpful assitant.answer the question: {question}"
prompt = PromptTemplate(template=prompt_template, input_variables=["question"])

llm = OpenAI(model="gpt-3.5-turbo")
llm_chain = LLMChain(llm=llm,prompt=prompt)


st.title("LangChain App")
question = st.text_input("enter  your question:")
if question:
  response = llm_chain.run({"question":question})
  st.write("Response: {response}")

# !pip install langchain_community
